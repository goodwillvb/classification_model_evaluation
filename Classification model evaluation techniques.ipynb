{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the dataset\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# doing a 70-30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting logistic regression to predict fraudulent transactions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression(random_state=1, max_iter=1000)\n",
    "\n",
    "# fitting the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data model score: 0.9991773840813788\n",
      "\n",
      "Test data model score: 0.9991222218320986\n"
     ]
    }
   ],
   "source": [
    "# scoring the model\n",
    "\n",
    "print(f'Training data model score: {logreg.score(X_train, y_train)}')\n",
    "print()\n",
    "print(f'Test data model score: {logreg.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We got terrific accuracy on the dataset. Let's examine the target class frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    85308\n",
      "1      135\n",
      "Name: Class, dtype: int64\n",
      "0    199007\n",
      "1       357\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())\n",
    "\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is clearly a class imbalance here with very few number of fraudulent transactions happening (class =1)\n",
    "\n",
    "#### Thus, we cannot rely solely on the model accuracy as the evaluation metric.\n",
    "\n",
    "- According to this model, with target class imbalance, if this predicts a particular transaction to be non-fraudulent, it will be accurate 99.9177% of the times!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive deeper into our results. In binary classification, there are four possible outcomes:\n",
    "\n",
    "1. **True Positive (TP)**: Model predicts that $x$ belongs to the positive class (1) and it is actually positive (1)\n",
    "\n",
    "2. **False Positive (FP)**: Model predicts that $x$  belongs to the positive class (1) but it is acually negative (0)\n",
    "\n",
    "3. **True Negative (TN)**: Model predicts that $x$ belongs to the negative class (0) and it is actually negative (0)\n",
    "\n",
    "4. **False Negative (FN)**: Model predicts that $x$ belongs to the negative class (0) but it is acually positive (1)\n",
    "\n",
    "If we put these outcomes in a matrix, we arrive at what is known as a confusion matrix:\n",
    "\n",
    "|   .  |  Predicted Class 0/-  |   Predicted Class 1/+  | \n",
    "| --------- |:---:|:---:|\n",
    "|Actual Class 0/-|**TN** | **FP** | \n",
    "|Actual Class 1/+|**FN** |**TP** | \n",
    "\n",
    "\n",
    "- The goal of a classification model is to ultimately minimize misclassification i.e minimize FP and FN\n",
    "\n",
    "Using these definitions, accuracy can be written as:\n",
    "\n",
    "$$Accuracy = \\frac{TN+TP}{TN+FP+FN+TP}$$\n",
    "\n",
    "Lets get the confusion matrix for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85292,    16],\n",
       "       [   59,    76]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = logreg.predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_predicted)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing confusion matrix\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8c619530d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix_display = ConfusionMatrixDisplay(matrix, display_labels=['0', '1'])\n",
    "matrix_display.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets interpret this confusion matrix\n",
    "\n",
    "\n",
    "|   .  |  Predicted Non-fraudulent (0/-)  |   Predicted Fraudulent (1/+)  | \n",
    "| --------- |:---:|:---:|\n",
    "|True Non-fraudulent (0/-) |85292 | 16 | \n",
    "|True Fraudulent (1/+) |59 |76 | \n",
    "\n",
    "\n",
    "* **TN**: Model classified 85,292 legitimate(non-fraudulent) transactions that were indeed non-fraudulent\n",
    "* **FP**: Model classified 16 transactions as fraudulent that were actually non-fraudulent\n",
    "* **FN**: Model classified 59 transactions as non-fraudulent that were actually fraudulent\n",
    "* **TP**: Model classified 76 fraudulent transactions that were indeed fraud\n",
    "\n",
    "\n",
    "The goal is to identify the frauds (class 1). Out of 135 (76+59) total fraudulent transactions in the test data, the model correctly identified only 76 or 56% of such transactions.\n",
    "\n",
    "Moreover 16 transactions were misclassified as fraud. \n",
    "\n",
    "These are serious oversights in this model, with only 56% of the frauds being correctly identified by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "\n",
    "Because of the fact that accuracy alone can be misleading depending on the class balance of the data, alternative metrics which consider the relative proportions of correct and incorrect classifications in both the positive and negative classes. Two of the most common are *precision* and *recall*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**: whenever you are concerned about the impact of *False Positives*, precision metric should be evaluated.\n",
    "\n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "TP+FP: total number of positive classifications **done by the model**\n",
    "\n",
    "Precision measures that out of all **positive predictions** by the model, how many datapoints are truly positive. \n",
    "\n",
    "For Precision, think about **prediction** as the basis of evaluation.\n",
    "\n",
    "- Higher # of FP -> Lower Precision\n",
    "\n",
    "- Lower # of FP -> Higher Precision\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Recall**: whenever you are concerned about the impact of *False Negatives*, recall metric should be evaluated.\n",
    "\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "TP+FN: total number of classification belonging to **actual/true positive class**\n",
    "\n",
    "Recall measures that out of all the datapoints belonging to acual positive class, **how many points were correctly identified by the model as positives**\n",
    "\n",
    "For recall, think about **actual/true data** as the basis of evaluation.\n",
    "\n",
    "- Higher # of FN -> Lower Recall\n",
    "\n",
    "- Lower # of FN -> Higher Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Back to our model\n",
    "\n",
    "|   .  |  Predicted Non-fraudulent (0/-)  |   Predicted Fraudulent (1/+)  | \n",
    "| --------- |:---:|:---:|\n",
    "|True Non-fraudulent (0/-) |85292 | 16 | \n",
    "|True Fraudulent (1/+) |59 |76 | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**: Out of 92 transactions predicted by the model as fraudulent/+, 76 were indeed truly fraudulent/+.\n",
    "$$Precision = \\frac{76}{76+16} = \\frac{76}{92}= 82.60\\%$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**: Out of 135 transactions belonging to fradulent/+ class, 76 were correctly identified by the model as fraudulent/+\n",
    "$$Recall =\\frac{76}{76+59} = \\frac{76}{135} = 59.29\\%$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Precision: 0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "# obtaining Precision score\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(f\"Model's Precision: {precision_score(y_test, y_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Recall: 0.562962962962963\n"
     ]
    }
   ],
   "source": [
    "# obtaining Recall score\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(f\"Model's Recall: {recall_score(y_test, y_predicted)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100% Precision**: means that all of the transactions classified by the model as fraudulent/+ are indeed fraudulent. The model is very precise in predicting fraud.\n",
    "\n",
    "**0% Precision**: means that of all the transactions classified by the model as fradululent/+, none of the transactions are actually fraudulent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100% Recall**: means that off all the true fraudulent/+ transactions, the model is able to correctly classify all of the transactions as fraudulent.\n",
    "\n",
    "**0% Recall**: means that off all the true fraudulent/+ transactions, the mode is unable to classifiy any transaction as fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I am able to recall every fraud, I could be also calling a lot of non-fraudulent transactions fraud. This means that my precision would be lower. We have an imprecise model (_i.e._ there are more false positives) but one that is very likely to predict all instances of fraud which did occur, at the expense of incorrectly labeling some legitimate transactions fraudulent.\n",
    "\n",
    "If everything I predict to be a fraud is fraud, it doesn't necessarily mean that I am capturing all of the fraudulent transactions, only that I am very confident in my predictions of which transactions are fraudulent. This means that my recall would be lower. I have a highly precise model, but at the expense of missing many of the fraudulent transactions which may have occurred (_i.e._ there are more false negatives).\n",
    "\n",
    "So, we can improve either at the expense of the other. There is always a trade-off between precision and recall, between correctly predicting the positive and negative classes.\n",
    "\n",
    "Another common metric that combines the two measures is the $F_1$ score:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$$\n",
    "\n",
    "\n",
    "The F1 score is the harmonic average of the precision and recall. An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "\n",
    "There is no intuitive explanation of the F1 score. We use the F1 score in order to try and maximize the precision and recall scores. Models with a higher F1 score are usually better at predicting the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669603524229075"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the very handy `classification_report` function in `sklearn.metrics` will compute precision, recall, and $F_1$ score for both the positive and negative classes in a nicely formatted output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85308\n",
      "           1       0.83      0.56      0.67       135\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.91      0.78      0.83     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_predicted)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Rate, False Positive Rate\n",
    "\n",
    "For classifiers such as Logistic Regression, by varying the threshold at which we consider a point to be classified into the positive class, we can tailor the model to have higher precision or recall depending upon the nature of the problem or domain knowledge. \n",
    "\n",
    "For example, if the threshold is set at 0.5, it means the model classifies a datapoint to class 1 if the predicted probability is higher that 0.5.\n",
    "\n",
    "If the threshold is lowered to say 0.4, the more datapoint are likely to be classified by the model into the positive class. This would also mean that some of the negative class points could also be incorrectly classified to positive class. Lowering the threshold typically **increases both true positives and false positives**.\n",
    "\n",
    "If the threshold is increased to say 0.7, the more datapoints are likely to be classified into the negative class, leading to some positive points incorrectly classified to negative. Increasing the threshold typically **increases both true negatives and false negatives**.\n",
    "\n",
    "Lets see how varying the threshold affects the precision and recall of this model. I have used 'predict_proba' method of logistic regression model to get the probability scores and then manually assigned the probabilites to respective classes based on chosed threshold cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99001890e-01, 9.98109725e-04],\n",
       "       [9.99984501e-01, 1.54987533e-05],\n",
       "       [9.99938414e-01, 6.15855879e-05],\n",
       "       ...,\n",
       "       [9.98744727e-01, 1.25527347e-03],\n",
       "       [9.99915140e-01, 8.48600248e-05],\n",
       "       [9.99333894e-01, 6.66106093e-04]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)\n",
    "# the first value is the prob. of datapoint belonging to 0\n",
    "# second values is the prob. of datapoint belonging to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.98109725e-04, 1.54987533e-05, 6.15855879e-05, ...,\n",
       "       1.25527347e-03, 8.48600248e-05, 6.66106093e-04])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using second value..belonging to class 1\n",
    "y_proba = logreg.predict_proba(X_test)[:,1]\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold = 0.5\n",
      "Precision score: 0.8260869565217391\n",
      "Recall score: 0.562962962962963\n"
     ]
    }
   ],
   "source": [
    "# precision and recall using 0.5 as threshold\n",
    "y_thresh = np.where(y_proba > 0.5, 1, 0) #prob values > 0.5 assigned 1\n",
    "print('At threshold = 0.5')\n",
    "print(f'Precision score: {precision_score(y_test, y_thresh)}')\n",
    "print(f'Recall score: {recall_score(y_test, y_thresh)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold = 0.8\n",
      "Precision score: 0.8625\n",
      "Recall score: 0.5111111111111111\n"
     ]
    }
   ],
   "source": [
    "# at 0.8 threshold\n",
    "y_thresh = np.where(y_proba > 0.8, 1, 0)\n",
    "print('At threshold = 0.8')\n",
    "print(f'Precision score: {precision_score(y_test, y_thresh)}')\n",
    "print(f'Recall score: {recall_score(y_test, y_thresh)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At threshold = 0.2\n",
      "Precision score: 0.6885245901639344\n",
      "Recall score: 0.6222222222222222\n"
     ]
    }
   ],
   "source": [
    "# at 0.2 threshold\n",
    "y_thresh = np.where(y_proba > 0.2, 1, 0)\n",
    "print('At threshold = 0.2')\n",
    "print(f'Precision score: {precision_score(y_test, y_thresh)}')\n",
    "print(f'Recall score: {recall_score(y_test, y_thresh)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision**\n",
    "At lower threshold (0.2), many points are classified as positive and many points that are actually negative are also classified incorrectly as positive -> increasing false positives. Since FPs increase, the overall precision score decreases quite a bit (compared to 0.5 threshold).\n",
    "\n",
    "At higher threshold (0.8), there are very few incorrectly classified positives -> reduced number of false positives. Since FPs decrease, the overall precision score increases compared to 0.5 threshold. The model is getting more precise in classifing the positive as truly positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** At lower threshold(0.2), many points are classified positive including increase in false positives. This also means that there is lower probability for the model to classify false negatives. Since FNs are fewer, the overall recall increases compared to 0.5 threshold.\n",
    "\n",
    "At higher threshold(0.8), many points are classified negatives with posible increase in false negatives. Since FNs are more numerous, the overall recall score decreases compared to 0.5 thereshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
